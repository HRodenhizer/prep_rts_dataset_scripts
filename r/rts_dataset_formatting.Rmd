---
title: "RTS Dataset Formatting"
author: "Heidi Rodenhizer"
date: "`r Sys.Date()`"
output: html_document
---

# TODO

-  add update of official data set's StabilizedRTS and MergedRTS columns? Should the stabilized/combined polygon get a link to the new/old polygon(s) in those columns?
-  Should output be only the new file or the combined datasets?
-  Have contributors make a branch named with lab name and date?
-  Make the script find and download the current version of the RTS dataset and metadata description rather than providing the filepath manually (or ask people to confirm that the latest changes have been pulled down prior to reading in data from the project)
- remove filepaths and metadata columns that I set
-  think through environment sharing (rts_dataset.rproj, .env, renv)
-  finalize file organization/filepaths so that they don't differ between R and Python

# Set-Up

```{r}
library(reticulate)
library(sf)
library(tidyverse)
```

## User-Defined Input

Before starting, copy your new file into the input_data directory.
Provide the file name of the new data:

```{r}
new_data_file <- 'rts_dataset_test_polygons_new.shp'  # set this
new_data_filepath <- paste(
  'input_data',
  new_data_file,
  sep = '/')
```

Provide the names of any metadata fields in your new file that are not already in the official RTS Data Set (please check the list to ensure that the field has not been included previously):

```{r}
# Use the format `FullName = AbbreviatedName`, where the FullName should be a human-readable name and the AbbreviatedName should be the ESRI shapefile driver abbreviated version of the the FullName.
# Example:
# new_fields <- c('CustomColumn1' = 'CstmCl1')
new_fields <- c('CustomColumn1' = 'CstmCl1')
```

Have you already created RTS centroid columns, or would you like them to be created within this script? Provide either TRUE, if the columns do not exist yet, or FALSE, if you have already created them:

```{r}
# Example: 
# calculate_centroid <- FALSE
calculate_centroid <- FALSE
```


# Functions

## add_empty_columns

```{r}
add_empty_columns <- function(df, column_names) {
  for (name in column_names) {
    if (!name %in% colnames(df)) {
      df <- df |>
        mutate(!!!setNames(NA, name))
    }
  }
  return(df)
}
```

## check_intersection_info

```{r}
check_intersection_info <- function(df) {
  
  duplicated_uuids <- df |>
    as_tibble() |>
    select(UUID) |>
    summarise(count = n(),
              .by = UUID) |>
    filter(count > 1) |>
    pull(UUID)
  
  int_info_complete <- df |>
      mutate(
        int_info_complete = case_when(
          is.na(Intersections) & str_length(SelfIntersectionIndices) == 0 ~ TRUE,
          !is.na(Intersections) & (!is.na(RepeatRTS) | !is.na(MergedRTS) | !is.na(StabilizedRTS) | !is.na(AccidentalOverlap)) ~ TRUE,
          str_length(SelfIntersectionIndices) > 0 & UUID %in% duplicated_uuids ~ TRUE,
          TRUE ~ FALSE
        )
      )
  if (!all(int_info_complete$int_info_complete)) {
    
    print(
      int_info_complete |>
        filter(int_info_complete == FALSE)
      )
    
    stop('Incomplete information provided about intersecting RTS polygons. Please complete information for rows printed above.')
  }
  
  print('Intersection information is complete.')
  
}
```

## get_earliest_uuid

Return `UUID` from feature with earliest `BaseMapDate` for features in `new_data` that overlap eachother.

```{r}
get_earliest_uuid <- function(df, index_col, self_intersections_col) {
  
  indices <- c(index_col,
           as.numeric(split_string_to_vector(self_intersections_col)))
  
  return(
    df |>
      slice(indices) |>
      filter(BaseMapDate == min(BaseMapDate)) |>
      pull(UUID)
  )
  
}
```

## get_uuids_by_index_string

```{r}
get_uuids_by_index_string <- function(index_string, df) {
  str_flatten(df |>
                slice(as.numeric(
                  str_split(index_string, ',') |>
                    pluck(1))
                ) |>
                pull(UUID) |>
                unique(),
              collapse = ',')
}
```

## run_formatting_checks

```{r}
check_lat <- function(lat) {
  
  correct_type <- class(lat) == 'numeric'
  missing_values <- any(is.na(lat))
  reasonable_values <- all(lat >= -180 & lat <= 180)
  
  if (!correct_type) {
    stop('The CentroidLat column is not numeric. Ensure that latitude is reported as decimal degress in WGS 84.')
  } else if (missing_values) {
    stop('The CentroidLat column is missing values.')
  } else if (!reasonable_values) {
    stop('Unexpected values found in the CentroidLat column. Ensure that CentroidLat is listed as decimal degress in WGS 84.')
  }
}

check_lon <- function(lon) {
  
  correct_type <- class(lon) == 'numeric'
  missing_values <- any(is.na(lon))
  reasonable_values <- all(lon >= -90 & lon <= 90)
  
  if (!correct_type) {
    stop('The CentroidLon column is not numeric. Ensure that longitude is listed as decimal degress in WGS 84.')
  } else if (missing_values) {
    stop('The CentroidLon column is missing values.')
  } else if (!reasonable_values) {
    stop('Unexpected values found in the CentroidLon column. Ensure that CentroidLon is listed as decimal degress in WGS 84.')
  }
}

check_region <- function(region) {
  
  correct_type <- class(region) == 'character'
  missing_values <- any(is.na(region))
  
  if (!correct_type) {
    stop('The RegionName column is not a string.')
  } else if (missing_values) {
    stop('The RegionName column is missing values.')
  }
}

check_creator <- function(creator) {
  
  correct_type <- class(creator) == 'character'
  missing_values <- any(is.na(creator))
  
  if (!correct_type) {
    stop('The CreatorName column is not a string.')
  } else if (missing_values) {
    stop('The CreatorName column is missing values.')
  }
}

check_contribution_date <- function(contribution_date) {
  
  correct_type <- class(contribution_date) == 'Date'
  missing_values <- any(is.na(contribution_date))
  
  if (!correct_type) {
    stop('The ContributionDate column does not contain dates (or they are improperly formatted).')
  } else if (missing_values) {
    stop('The ContributionDate column is missing values.')
  }
}

check_basemap_date <- function(basemap_date) {
  
  correct_type <- all(
    as.logical(
      map(
        basemap_date |>
          str_split(pattern = ','),
        ~ class(
          .x |>
            dmy()
        ) == 'Date'
      )
    )
  )
  missing_values <- any(is.na(basemap_date))
  
  if (!correct_type) {
    stop('The BaseMapDate column does not contain dates (or they are improperly formatted).')
  } else if (missing_values) {
    stop('The BaseMapDate column is missing values.')
  }
}

check_source <- function(source) {
  
  correct_type <- class(source) == 'character'
  missing_values <- any(is.na(source))
  
  if (!correct_type) {
    stop('The BaseMapSource column is not a string.')
  } else if (missing_values) {
    stop('The BaseMapSource column is missing values.')
  }
}

check_resolution <- function(resolution) {
  
  correct_type <- class(resolution) == 'numeric'
  missing_values <- any(is.na(resolution))
  
  if (!correct_type) {
    stop('The BaseMapResolution column is not numeric.')
  } else if (missing_values) {
    stop('The BaseMapResolution column is missing values.')
  }
}

check_train_class <- function(train_class) {
  
  correct_type <- class(train_class) == 'character'
  missing_values <- any(is.na(train_class))
  
  if (!correct_type) {
    stop('The TrainClass column is not a string.')
  } else if (missing_values) {
    stop('The TrainClass column is missing values.')
  }
}

run_formatting_checks <- function(df) {
  check_lat(df$CentroidLat)
  check_lon(df$CentroidLon)
  check_region(df$RegionName)
  check_creator(df$CreatorLab)
  check_contribution_date(df$ContributionDate)
  check_basemap_date(df$BaseMapDate)
  check_source(df$BaseMapSource)
  check_resolution(df$BaseMapResolution)
  check_train_class(df$TrainClass)
  
  print('Formatting looks good!')
}
```

## split_string_to_vector

```{r}
split_string_to_vector <- function(uuid_string) {
  uuid_string |>
    str_split(',') |>
    pluck(1)
}
```


# Import Metadata Description File

```{r}
### update this to download the current version automatically ##################
col_metadata <- read_csv('input_data/metadata_description.csv')
################################################################################

required_fields <- col_metadata |>
  filter(Required == TRUE) |>
  select(FullColumnName, AbbreviatedColumnName) |>
  deframe()

optional_fields <- col_metadata |>
  filter(Required == FALSE) |>
  select(FullColumnName, AbbreviatedColumnName) |>
  deframe()

all_fields <- c(required_fields, optional_fields, new_fields)
```


# Import Official and New RTS Data Files
If you get the error 'Error in `all_of()`: ! Can't subset columns that don't exist. âœ– Column `{required_column}` doesn't exist.', check to make sure that all of the required columns (except UUID, and optionally CentroidLat and CentroidLon) and new columns are present and named correctly in your shapefile of new RTS features.

```{r}
### update this to find the dataset online and download it #####################
rts_data_filepath <- paste(
  'input_data',
  'rts_dataset_test_polygons_current.shp',
  sep = '/'
  )

rts_data <- read_sf(rts_data_filepath) |>
  select(all_of(c(!!!required_fields)),
         any_of(c(!!!optional_fields)))
################################################################################

if (calculate_centroid) {
  
  new_data <- read_sf(new_data_filepath)
  new_data <- new_data |>
    bind_cols(
    st_coordinates(
      st_centroid(
        new_data
      ) |>
          st_transform('EPSG:4326')
    )
  ) |>
  rename(CntrdLt = X, CntrdLn = Y) |>
    select(
      all_of(
        c(!!!required_fields[
          which(names(required_fields) != 'UUID')
        ]
        )
      ),
      any_of(c(!!!optional_fields)),
      all_of(c(!!!new_fields)))
  
} else if (!calculate_centroid) {
  
  new_data <- read_sf(new_data_filepath) |>
    select(
      all_of(
        c(!!!required_fields[
          which(names(required_fields) != 'UUID')
        ]
        )
      ),
      any_of(c(!!!optional_fields)),
      all_of(c(!!!new_fields)))
  
}
```


# Check Metadata Format of New Data

```{r}
run_formatting_checks(new_data)
```


# Generate UUIDs

Set seed for UUID generation (R) by concatenating all required metadata columns (except UUID) into a single string
```{r}
new_data <- new_data |>
  rowwise() |>
  mutate(
    seed = str_flatten(
      c(
        round(CentroidLat, 13),
        round(CentroidLon, 13),
        RegionName,
        CreatorLab,
        format(ContributionDate, '%d-%m-%Y'),
        BaseMapDate,
        BaseMapSource,
        BaseMapResolution,
        TrainClass
      )
    ),
    .after = TrainClass
  ) |>
  ungroup()

new_seeds <- pull(new_data, seed)
```

Generate UUIDs (Python via reticulate package)
```{python}
import uuid
```

```{python}
new_uuids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, name = seed)) for seed in r.new_seeds]
r.new_uuids = new_uuids
```

Add UUIDs to New RTS Data (R)
```{r}
new_data <- new_data |>
  mutate(UUID = new_uuids,
         .after = seed)
```

# Check for Intersections with RTS Data Set

Find intersecting RTS polygons from the official RTS data set and retrieve their UUIDs. Create an empty column for the UUIDs of polygons that have been repeated that will be manually populated.
```{r}
overlapping_data <- new_data |>
  mutate(
    Intersections = map_chr(
      st_intersects(new_data,
                    rts_data,
                    sparse = TRUE),
      ~ str_flatten(.x, collapse = ',')
    ),
    .after = colnames(new_data)[length(which(colnames(new_data) != 'geometry'))]
  ) |>
  filter(str_length(Intersections) > 0) |>
  rowwise() |>
  mutate(
    Intersections = get_uuids_by_index_string(Intersections, rts_data),
    .after = Intersections
  ) |>
  ungroup()

if (nrow(overlapping_data) > 0) {
  
  if (!'RepeatRTS' %in% colnames(overlapping_data)) {
    
    overlapping_data <- overlapping_data |>
      mutate(RepeatRTS = NA)
    
  } else if (!'StabilizedRTS' %in% colnames(overlapping_data)) {
    
    overlapping_data <- overlapping_data |>
      mutate(StabilizedRTS = NA)
    
  } else if (!'MergedRTS' %in% colnames(overlapping_data)) {
    
    overlapping_data <- overlapping_data |>
      mutate(MergedRTS = NA)
    
  }
  
  overlapping_data <- overlapping_data |>
      mutate(AccidentalOverlap = NA)
  
  write_sf(overlapping_data,
           paste('r_output',
                 paste0(
                   str_split(new_data_file, '\\.')[[1]][1],
                   '_overlapping_polygons.shp'),
                 sep = '/'))
  
}
```

At this point, you will need to manually check all polygons with intersections against the polygons in the official RTS data set in your preferred GIS software and save the output to `r paste0(str_split(new_data_file, '\\.')[[1]][1], '_overlapping_polygons_edited.shp')` (press Ctrl+Enter while cursor is in the preceding in-line code chunk to see the actual file name, rather than the code to produce the file name).  When possible/necessary, try to find imagery that matches the date of the intersecting polygons - this may require contacting the lab that did the original delineation.

Your job is to inspect each of the polygons listed in the 'Intersections' column compared to the new RTS feature and manually copy and paste the UUIDs from the 'Intersections' column into the 'RepeatRTS', 'StabilizedRTS', 'MergedRTS', or 'AccidentalOverlap' based on the relationship between the two polygons.

- Paste the UUID into the RepeatRTS column when the new RTS feature is the same RTS feature as the RTS feature in the 'Intersections' column, but was delineated at a different point in time, by a different lab at the same point in time, or from different imagery at the same point in time. The RTS feature is the same when it was the result of the same RTS initiation event.

- Paste the UUID into the StabilizedRTS column when the RTS feature in the 'Intersections' column is a stabilized RTS scar as of the date of the imagery used in the new RTS delineations.

- Paste the UUID into the MergedRTS column when multiple RTS features in the 'Intersections' column merged to form the new RTS feature.

- Paste the UUID into the AccidentalOverlap column when inaccuracies in delineation of separate RTS features lead to overlap (e.g. features that are very close to each other and the polygons barely touch). 

When this is done, each of the UUIDs in the Intersections column should have been copied into one (and only one) of the 'RepeatRTS', 'StabilizedRTS', or 'MergedRTS' columns.


# Load Manually Edited File and Join to New Data

Add the 'RepeatRTS', 'StabilizedRTS', and 'MergedRTS' columns that you just edited back into `new_data`.

```{r}
edited_file <- paste('r_output', 
                     paste0(
                       str_split(new_data_file, '\\.')[[1]][1], 
                       '_overlapping_polygons_edited.shp'
                     ), 
                     sep = '/')

if (file.exists(edited_file)) {
  
  overlapping_data <- read_sf(edited_file) |>
    select(all_of(c(!!!required_fields)),
           all_of(c(!!!optional_fields[
             which(names(optional_fields) %in% c('StabilizedRTS', 'MergedRTS'))
           ])),
           any_of(c(!!!optional_fields[
             which(!names(optional_fields) %in% c('StabilizedRTS', 'MergedRTS'))
           ])),
           all_of(c(!!!new_fields)),
           seed,
           Intersections = matches('^I.+t', ignore.case = FALSE),
           RepeatRTS = matches('^R.+RTS', ignore.case = FALSE),
           AccidentalOverlap = matches('Ac.+O', ignore.case = FALSE))

new_data <- new_data |>
  full_join(overlapping_data |>
              st_drop_geometry(),
            by = colnames(new_data |>
                             st_drop_geometry())) |>
  mutate(UUID = case_when(is.na(RepeatRTS) ~ UUID,
                          !is.na(RepeatRTS) ~ RepeatRTS)) |>
  select(!matches('geometry')) # doesn't actually remove geometry column, but makes sure it is the last column after the join

} else {
  
  new_data <- new_data |>
    mutate(RepeatRTS = NA,
           StabilizedRTS = NA,
           MergedRTS = NA,
           AccidentalOverlap = NA) |>
    select(!matches('geometry'))
  
  warning('No manually edited file has been imported. This is okay if there were no overlapping polygons, but is a problem otherwise.')
}
```

# Check for Intersections within New RTS Data Set

Intersections within the new data set are assumed to be repeat delineations of the same RTS feature. If this is not true (e.g. if you have delineated an old RTS scar and an active RTS feature on top of it), this code will not assign UUIDs properly. In this case, please get in touch with us to determine how to proceed.

```{r}
new_data <- new_data %>%
  mutate(
    idx = seq(1:nrow(new_data)),
    # get all intersections for each RTS feature (excluding itself)
    SelfIntersectionIndices = map_chr(
      st_intersects(x = new_data, remove_self = TRUE),
      ~ str_flatten(.x, collapse = ',')
    ),
    UUID = case_when(
      str_length(
        SelfIntersectionIndices
      ) == 0 | UUID == RepeatRTS ~ UUID,
      str_length(
        SelfIntersectionIndices
      ) > 0 ~ get_earliest_uuid(., 
                                idx,
                                SelfIntersectionIndices)
    ),
    .after = RepeatRTS
  )
```


# Check Completeness of Intersection Information

```{r}
check_intersection_info(new_data)
```


# Final Column Selection

```{r}
new_data <- new_data |>
  add_empty_columns(
    names(
      optional_fields[
        which(!names(optional_fields) %in% c('StabilizedRTS', 'MergedRTS'))
        ]
      )
    ) |>
  select(names(all_fields))
```

# Save Formatted File as a Shapefile

```{r}
write_sf(new_data,
         paste('r_output', 
               paste0(
                 str_split(new_data_file, '\\.')[[1]][1], 
                 '_formatted.shp'), 
               sep = '/'))
```

Now you are ready to submit `r paste0(str_split(new_data_file, '\\.')[[1]][1], '_formatted.shp')`!